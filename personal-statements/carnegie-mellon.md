---
documentclass: article
geometry:
  - margin=1.5in
---

<!--
pandoc carnegie-mellon.md -o carnegie-mellon.pdf
-->

<!--
0. RTFAF: Read The Fine Application Form. Don't write a one-size-fits-all-univs SOP.
1. State upfront who you are and what you want. One should not have to search using a word processor whether you want an MS or a Ph.D.
2. Tell what you intend doing with your degree. Inevitably, this boils down to a suitable permutation of words from the set {creative, career, industry, academia, research, professor, university, lab,startup}.
3. Avoid hot air. Adjectives like thrill, passion, excitement, joy, etc., should be avoided like the plague. Explain what you expect from grad school. Of course, we all want a job, but try putting it down as politically correctly as you can.
4. Avoid quotations. You may have "miles to go before you sleep", "chosen the road less travelled", or "your-favourite-cliche-quote-from-high-school-here", but it ain't a personal statement unless you are quoting yourself, is it ?
5. Use simple English. Resist the temptation to use your new-found vocabulary from the GRE word lists.
6.Describe your experience. Don't say you were introduced to CS as a suckling infant, you started speaking in Python before your mother tongue, yada, yada, yada... No one actually cares for your experience as a kid, so keep it brief.
7. The most important experience you would've had would be your undergrad. Of course, I mean academic work. As an aside, I firmly believe that the day you really graduate is the day you realise you wasted four years. Describe your coursework tersely.
8. Explain a select few projects you did in gory detail and why that got you interested in research. This is a point of much debate. Personally, I like explaining things in detail while many people prefer "high level" stuff. The catch with my way is that you could say something blatantly wrong and possibly screw up your chances completely. Again, I feel that if someone knows what the hell she is talking about, she should be confident enough to sell what she did. I suggest you show your SOP to profs, preferably those who are writing your letters, to make sure you are not shooting yourself in the foot with amazing accuracy.
9. Articulate why you choose to work in the area you want to work on. For example, kernel hacking gives you the high, your best buddy is the memory allocator, etc., so you want to work in O/S. Or, you increase your treadmill speed like TCP increases its cwnd, you do a packet sniff to find out protocols used instead of chatting in a messenger, your concept of networking is making computers talk, so you want to work in networks. In particular, it will be ideal if it was something you did best. I've heard of a case where someone said the thing she did best was cooking. The story goes she baked a cake and sent it to the admissions committee. Harvard, rumour has it, fell hook, line, and sinker for this. The professors in CS@UM most likely don't care for your culinary expertise, in case this gives you ideas.
9.1 You could possibly angle for more than one area. If you can show some prior work, or what you can do, in more than one area, you are good. However, you should avoid things like "I like theory, systems, AI, and NC very much. Graphics and Software, a little less".
10. Once you've explained why you like some area(s), explain how you will fit in with work being done in *that* univ. Say how you, Prof.Foo, and Prof.Bar can attain the holy grail of networking together. You should appear in awe of them, yet appear indispensable to their work. Avoid mentioning persons alone, i.e., qualify a professor by the group he leads/is part of. You can rest assured any CS prof will be part of some group with what she thinks is a cool abbreviated name. This way you won't antagonise a rival professor in the same area who actually sits on the committee.
11. Market yourself with concrete statistics. I won't believe it myself if you claim you are the second coming of Knuth. It is very unlikely that the profs of a dept. will. After all, it is their fate to have seen a billion SOPs before yours and see many more after yours. That said, mention things like "I was ranked in the top 0.123% of the FOO exam conducted by the BARs." exactly once.
 -->

# Instructions

Prepare a concise one or two page essay in PDF format that describes your primary areas of interest, your related experiences, and your objective in pursuing a graduate degree at Carnegie Mellon. Your essay should be specific in describing your interests and motivations. When describing your interests, you should explain why you think they are important areas of study and why you are particularly well-suited to pursue them. You should describe any relevant education, research, commercial, government, or teaching experience. If you are applying to more than one program, you may (but are not required to) submit a separate Statement of Purpose for each program. If you are submitting different statements, please upload as one file and include a table of contents page. Include your name and User ID on the essay.

_Master's in Computer Science applicants:_ Discuss your purpose in pursuing a master's degree in Computer Science. For example, you might explain how advanced study in Computer Science fits into your future career ambitions. There are no right answers, and you do not need to have worked out your future plans in detail. We just want to see that you have thought your purpose through. If your background is unusual, this is also the right place to explain it to us.

# Essay

I'm utterly fascinated by artificial intelligence. More specifically, my main area of interest is natural language understanding. Not only is it difficult to teach a system to understand natural language (like an essay on economics), it's difficult to prove that the system understands the material (how do you ask a machine to explain supply and demand?). To me, natural language understanding is a very fundamental area of artificial intelligence, because it needs a clear definition of comprehension and intelligence to measure success. I find natural language understanding so interesting because of this intertwining of teaching a computer to read with the underlying definition of intelligence. But beyond my own personal interest, teaching a computer to read and understand text is an important problem with massive potential benefits to the world. If a computer could read every cancer research study performed, along with dozens of textbooks on chemistry and biology, it would be in a much better position to cure cancer than any single human. And that sort of thinking applies to teaching, global policy and electric car development. Teaching a computer how to read would change the world for the better.

My undergraduate research thesis focuses on natural language understanding. I am creating a distantly-supervised dataset of sentences from academic writing using papers published on the arXiv[^arxiv]. With this dataset, I am fine-tuning transformer models to predict whether a given sentence needs editing or not. Finally, I'm benchmarking my model against top models from the Automatic Evaluation of Scientific Writing (AESW) task, which was also to predict whether a sentence in an academic context needs editing or not. The initial training set for the AESW provided 1.1M hand-edited sentences; the arXiv has around 150M sentences. Although these sentences are not hand-labeled, my thesis is about investigating whether that the size will make up for any potential noise in the data.

[^arxiv]: https://arxiv.org

Users of the arXiv typically upload PDFs and LaTeX source documents as `.tar.gz` files for each version of a paper. One specific challenge that I encountered was finding the best way to extract text from LaTeX source documents. The difficulty arises from LaTeX's Turing-completeness; there are arbitrarily complex expressions that eventually resolve to formatted text. To solve this, I manually inspected the output of three different "de-LaTeXing" (detexing) tools, line by line, keeping track every error. With these errors, I created an extensive test suite to ensure that my detexing tool was the best it could be. This software engineering skill and attention to fine detail led to a high-quality dataset that I am using to train my model.

My thesis has been the most interesting project I've worked on in my four years of professional programming, personal hobby projects, and school work. I'm teaching the computer how to read, and that feeling is so indescribably cool to me. Yes, my thesis is a joy to work on because I think that natural language understanding is important and that I can meaningfully contribute to the field. But beyond that, I also enjoy the rigor and difficulty of research. I'm forced to support my assumptions with analysis, and explain myself clearly and concisely. I've learned how to read academic papers and find the information relevant to my work. The independence and lack of safety net in research compared to my classes is scary, but thrilling. My work matters, and I'm responsible for making sure it's trustworthy and useful to others.

To me, a graduate degree is about improving both the breadth and the depth of my knowledge. For instance, I have known unknowns (I'm not entirely sure why transformer models are so effective) and unknown unknowns (I just learned that distributed algorithms exist). I feel confident that I can make my known unknowns into just knowns: I can find an online course, a textbook, or an open source project to learn from. But what unknown unknowns are out there that I've never heard about? In this sense, a graduate degree is about increasing my breadth of knowledge, so that when I have a new problem, I can find the best tool for the job.

In addition to increasing my breadth of knowledge, a graduate degree is an opportunity for me to become an expert in a topic and further develop my passion for natural language understanding. I think that we need to take more inspiration from nature to develop more and more powerful natural language understanding models. As children, we hear and process language for years before we demonstrate any understanding. For artificial models to demonstrate similar, human levels of understanding, I think that we must develop systems that spend a "human"-length time (years) learning, sped up by additional compute power. At Carnegie Mellon, Dr. Tom Mitchell's Read the Web group and their never-ending learning systems (NELL and NEIL) are huge steps in this direction. Continuing to take inspiration from nature, I think that we need a better understanding of how our models work compared to our brains. Again, Dr. Mitchell's Brain Image Analysis group and their research comparing top neural language models with the human brain are unparalleled and are critical to our understanding. Editing text is an important aspect of natural language understanding because it requires critical analysis, and my experience with modeling edits would be invaluable to further understanding similarities between human brains and neural models. Carnegie Mellon is a premier computer science research institution, and I'd be ecstatic to get to learn from and work with leaders in the field of naturaly language understanding.

<!-- Alexa is not the end-game for artificial intelligence. The benefits of computers understanding natural language are staggering. I want to work on developing computers that understand natural language. Gathering information about a topic and distilling it until it's easily understood, then expanding that new kernel of information into something valuable is amazing. I feel incredibly lucky to work on natural language understanding research, and I want to continue that at Carnegie Mellon. -->

<!--
Artificial intelligence, in general, is the most important field in computer science right now. I look at computers as tools, machines that help myself and others achieve their goals. That might be learning how to play piano, memorizing vocabulary for a second language, or finding a good dinner recipe for tonight. And for those goals, we have made amazing improvements since the days of paper encyclopedias. But for goals like driving a car, summarizing the state of the world economy, or translating a menu from Chinese to French, traditional software doesn't work. Artificial intelligence approaches are the current leading solutions for these problems (and others like it).

More specifically, I am fascinated by natural language processing, and more specifically still, natural language _understanding_. Ordinary human language is so unbelieveably important to development of more and more useful computer-based tools. We, as humans, communicate through natural language, record our history in natural language and think in natural language (sometimes in a different language than we speak). Ordinary language is arguably one of the reasons humankind has been so successful as a species to date: our ability to communicate our intents clearly with complete strangers has allowed us to spread and work together like no other animal (ussing tools helped too).

But computers, perhaps our most powerful tool as a tool-based species, don't understand natural language. They can't reason about sentences the same way we can. When I talk about computers understanding ordinary language, my friends and family immediately think of HAL 9000 or Siri. I jump to explain that computers understanding natural language means computers working as therapists, medical researchers, politicians and teachers. As an example, current cancer research is published as long-form content, but the warehouses filled with servers around the world are unable to take advantage of this information. They could be creating new insights while we sleep. Congressmen and women might aim to improve the lives of their constituents, but they can't account for everyone. A computer that understands ordinary language could read every voter's letter and every economics paper published and propose laws based on a true understanding of the entire world, rather than the limited understanding a single person can have.

I'm a computer science student who interned at GE Digital and Microsoft. I created a mobile app with friends to sell student football tickets, which transferred \$165K worth of tickets between 7K students. I love software engineering, but only when it's supporting something important, like bettering humanity by teaching computers to understand natural language.

I lived in Switzerland for nearly 3 years, learning a second language (German) when I was 14. I continued that study with a German minor because languages fascinate me: the differences in grammar, the history of vocabulary, the nuances of slang and how a language changes over time is all so interesting to me. My passion for language lends itself well to understanding music as well: rap lyrics need to tell a story while rhyming, and having a consistent rhythm, and using vocabulary that makes the rapper a concrete person, rather than a voice on a speaker. Seeing how lyricists change English (or German) grammar to fit their stories into these constraints is another component of language that interests me.
-->
